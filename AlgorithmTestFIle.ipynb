{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the required modules\n",
    "\"\"\"\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from VisualOdometry import VisualOdometry\n",
    "from Camera import Camera\n",
    "import numpy as np\n",
    "from dataset import Dataset\n",
    "from itertools import compress\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['savefig.dpi'] = 280\n",
    "mpl.rcParams['figure.dpi'] = 280\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Init object\n",
    "\"\"\"\n",
    "matcher_parameters = dict(detector='orb',\n",
    "                          matcher='bf')\n",
    "path = '/home/cesar/Documents/Projects/Computer_Vision/TFG/Kitti_Dataset/dataset/sequences/00/image_0'\n",
    "vo = VisualOdometry(matcher_parameters, path)\n",
    "\"\"\" Performs first iteration\"\"\"\n",
    "vo.init_reconstruction(optimize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking local map method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vo.kitti.read_image()\n",
    "previous_image = vo.kitti.image_1.copy()\n",
    "points = vo.scene.cameras[vo.index].points\n",
    "print(\"Number of map points: {}\".format(len(vo.scene.structure)))\n",
    "# Lucas-Kanade optical flow\n",
    "mask, lk_prev_points, lk_next_points = vo.matcher.lktracker(previous_image, vo.kitti.image_2, points)\n",
    "print(\"Tracked points: {}\".format(len(lk_next_points)))\n",
    "# Compute F and E using the tracked points\n",
    "F = vo.FindFundamentalRansac(lk_next_points, points[mask])\n",
    "E = vo.E_from_F(F)\n",
    "# Create a new cam object\n",
    "pts1 = (np.reshape(points[mask], (len(points[mask]), 2))).T\n",
    "pts2 = (np.reshape(lk_next_points, (len(lk_next_points), 2))).T\n",
    "R, t = vo.get_pose(pts1.T, pts2.T,vo.cam.K, E)\n",
    "cam = Camera()\n",
    "cam.set_R(R)\n",
    "cam.set_t(t)\n",
    "cam.Rt2P(inplace=True)\n",
    "# Project local map\n",
    "vo.scene.add_camera(cam)\n",
    "kp_proj, projected_map = vo.scene.project_local_map(vo.index + 1, as_kp=True)\n",
    "print(kp_proj[0].pt[1] >1)\n",
    "kp_proj = [kp for kp in kp_proj if int(kp.pt[0])>0 ]\n",
    "kp_proj = [kp for kp in kp_proj if int(kp.pt[0]) < 1230 ]\n",
    "kp_proj = [kp for kp in kp_proj if int(kp.pt[1])>0 ]\n",
    "kp_proj = [kp for kp in kp_proj if int(kp.pt[1]) < 360 ]\n",
    "for point in kp_proj:\n",
    "    print(\"Point: {}\".format(point.pt))\n",
    "    #print(\"Point: {}\".format())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "camera1 = vo.scene.cameras[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Crop image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Dataset('/home/cesar/Documents/Projects/Computer_Vision/TFG/Kitti_Dataset/dataset/sequences/00/image_0')\n",
    "data.read_image()\n",
    "print(\"Wide: {}\".format(data.image_width))\n",
    "print(\"Height: {}\".format(data.image_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Find keypoints in the image (in the application this keypoints are the mappoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector = cv2.ORB_create(2000)\n",
    "patch_size = 80\n",
    "def kp_list_to_np( kp_list):\n",
    "        \"\"\" Transforms a list of Keypoints into a numpy ndarray\n",
    "\n",
    "        :param kp_list: List of KeyPoint_ objects\n",
    "        :type kp_list: List\n",
    "\n",
    "        :returns: A Numpy ndarray (nx2) with the KeyPoints coordinates\n",
    "        :rtype: Numpy ndarray\n",
    "\n",
    "        \"\"\"\n",
    "        temp = [item.pt for item in kp_list]\n",
    "        return np.asarray(temp)\n",
    "kp1, desc1 = detector.detectAndCompute(data.image_2, None)\n",
    "keypoints = kp_list_to_np(kp1)\n",
    "# Show the ROI where we will extract new keypoints\n",
    "roi1 = data.crop_image(np.asarray(keypoints[10]), np.array([patch_size, patch_size]), data.image_2, center=True)\n",
    "plt.scatter(x=[patch_size / 2], y=[patch_size / 2], c='r', s=20)\n",
    "img = plt.imshow(roi1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load a new image and crop it using as center a keypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.read_image()\n",
    "data.read_image()\n",
    "data.read_image()\n",
    "roi = data.crop_image(np.asarray(keypoints[10]), np.array([patch_size, patch_size]), data.image_2, center=True)\n",
    "img = plt.imshow(roi)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find new keypoints in this ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kp2, desc2 = detector.detectAndCompute(roi, None)\n",
    "keypoints2 = kp_list_to_np(kp2)\n",
    "# Create a vector of descriptors for the keypoint in question using np.tile\n",
    "desc_kp = np.tile(desc1[0], (len(kp2), 1))\n",
    "# Match tracked keypoint descriptor with all the new descriptors\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False) \n",
    "matches1 = matcher.knnMatch(desc_kp, desc2, 2) \n",
    "\n",
    "# Sort them in the order of their distance.\n",
    "matches = sorted(matches1, key = lambda x:x[0].distance)\n",
    "# Print best match coordinates\n",
    "print(keypoints2[matches[0][0].queryIdx])\n",
    "trackedpoint = keypoints2[matches[0][0].queryIdx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot in the new roi the tracked keypoint (center of the roi) and the best candidate\n",
    "\n",
    "Do this steps for all the map points in the local map and discard bad tracked points using Ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = plt.imshow(roi)\n",
    "plt.scatter(x=[patch_size / 2, int(trackedpoint[0])], y=[patch_size / 2, int(trackedpoint[1])], c='r', s=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keypoint = cv2.KeyPoint(x=2,y=3, _size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
